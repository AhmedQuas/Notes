### Spis treści
- [Chapter 3: Everything generates data](#chapter-3-everything-generates-data)

# Chapter 3: Everything generates data

`Big data` - huge amount of data that comes from technology devices like cell phones, computers, tablets, cash registers, autonomous car and other groups of sensors. Three characteristics of big data:
- `volume` - large amount of data
- `velocity` - an amount of data that is growing expotentially fast
- `variety` -  data generated in different formats

[Large date sets avaiable for free](https://www.forbes.com/sites/bernardmarr/2016/02/12/big-data-35-brilliant-and-free-data-sources-for-2016/#51f677fb54db)

Challanges of Big Data:
- `management` - to organize and collect data properly
- `security` - data valuable for enterprise must be kept secure and accessible for authorized users
- `redundancy` - backup and disaster recovery
- `analytics` - structured(spreadsheet, medical form) and unstructured should be analyzed
- `access` - accessible from anywhere and anytime

Where can we store and compute Big Data:
- `cloud computing` - collection of data centers
- `fog computing` - designed to keep the data closer to the source for pre-processing

`Distributed processing` - breaking large volume of data it into smaller pieces. These smaller data volumes are distributed in many locations to be processed by many computers with smaller processors.

Types of data scaling:
- `vertical` - giant disk arrays
- `horizontal` - computers in the distributed architecture

`Hadoop` - software created to deal with large volumes of data, it consist of:
- HDFS - Hadoop File System, a distributed, fault tolerant file system
- MapReduce - distributed way of processing data

>Hadoop features:
>- scalability - can easily scale from a five node cluster to a one thousand node cluster without excessively increasing the administrative burden
>- fault tolerance – Hadoop automatically replicates data across clusters to ensure data will not be lost. If a disk, node, or a whole rack fails, the data is safe.

Primary types of processed data:
- `transactional information` - used to analyze daily sales reports and production schedules to determine how much inventory to carry.
- `analytical information` - supports managerial analysis tasks like determining whether the organization should build a new manufacturing plant or hire additional sales personnel.

Sources of information:
- social media sites - Facebook, YouTube and Twitter
- web pages, search engines
- historical data from public and private archives
- metadata that is attached to emails, documents and pictures
- medical, insurance and tax forms
- genomics research using DNA 

Structured data formats:
- `CVS` - comma-separated values
- `XML`
- `JSON`

Unstructured data:
- audio
- video
- web pages
- tweets

`Data mining` - process of turning data into meaningful information by discovering patterns and relationships in large data sets.

Chart types:
- `line` - used for continuous set of data, the number of data point is high and we would like to show a trend in the data over time
- `column` - used to show value of data of a specific point and compare thta value across similar categories
- `bar` - similar to column chart they are positioned horizontally and vertically
- `pie` - show the composition of a static number, the number of categories should be kept to a minimum. Total sum of segments must equal to 100%.
- `scatter` - when we want to show correlation or distribution of large number data points

Big Data analytics tools:
- Knime
- OpenRefine
- RapidMiner
- Orange



---

<div>
<a href="chapter-02.md">Prev: Chapter 2</a>
</div>
<div align="right">
<a href="chapter-04.md">Next: Chapter 4</a>
</div>